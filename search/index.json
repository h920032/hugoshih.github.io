[{"content":"Docker使用小筆記 前言 Docker可以說是雲端技術中非常重要的一項專案，這個專案實現了Container技術，使得軟體的執行可以不在受系統環境限制，更加速了雲端技術中Microservice概念的發展，以下就簡單介紹常用的Docker指令。\n基本操作  離開但不關閉container：  1  crtl+p crtl+q   連著打\n 查看container列表  1  sudo docker container ls    進入container  1  sudo docker attach \u0026lt;ID\u0026gt;    關閉container  1  sudo container stop \u0026lt;ID\u0026gt;   Docker Image操作  查看image列表  1  sudo docker image ls    下載image  1  sudo docker pull \u0026lt;hub path\u0026gt;    Run  1  sudo docker run \u0026lt;--gpus all\u0026gt; \u0026lt;-it\u0026gt; \u0026lt;-p 80(local):80(docker)\u0026gt; \u0026lt;-v /data(local):/data(docker) \u0026lt;images\u0026gt; \u0026lt;command\u0026gt;    image commit  1  sudo docker commit \u0026lt;ID\u0026gt; \u0026lt;images name\u0026gt;   Reference https://larrylu.blog/step-by-step-dockerize-your-app-ecd8940696f4\n 在沒有sudo權限使用docker： https://docs.docker.com/engine/security/rootless/ docker儲存： https://peihsinsu.gitbooks.io/docker-note-book/content/docker-save-image.html docker run 操作： https://noob.tw/docker-basic/ docker port： https://www.runoob.com/docker/docker-run-command.html nvidia docker： https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/supported-tags.md https://www.celantur.com/blog/run-cuda-in-docker-on-linux/ https://docs.docker.com/engine/reference/commandline/run/#access-an-nvidia-gpu error解法： https://github.com/NVIDIA/nvidia-docker/issues/1243 x11 firefox docker： https://stackoverflow.com/questions/16296753/can-you-run-gui-applications-in-a-docker-container 指令大全： https://github.com/docker-library/php/issues/359 沒有中文的解法： https://github.com/docker-library/php/issues/359  ","date":"2022-05-30T14:56:58+08:00","image":"https://page.dipsyshih.com/p/docker%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%AD%86%E8%A8%98/000648630023_hu02fe1734605d73890f92a3bf4d63dd0a_6802511_120x120_fill_q75_box_smart1.jpg","permalink":"https://page.dipsyshih.com/p/docker%E4%BD%BF%E7%94%A8%E5%B0%8F%E7%AD%86%E8%A8%98/","title":"Docker使用小筆記"},{"content":"Linux終端機視窗管理工具tmux筆記 前言 一般在操作遠端的Linux主機時通常會使用SSH連線進去操作，然而若遇到需要執行一個不可中斷的指令但又不得不中斷SSH連線時，一般情況下會將該Process拉到背景執行或是使用視窗管理工具screen，而tmux則是另一個非常強大的視窗管理工具，可以在終端機中模擬視窗操作，包括視窗的切換、視窗的切割等等，以下就列出一些tmux常用到的一些指令。\n基本 進入tmux\n1  tmux   列出tmux視窗列表\n1  tmux ls   連接tmux使窗\n1  tmux attach -t 0   1  tmux attach -t database   建立一個名為database的視窗\n1  tmux new -s database   更改名稱\n1  tmux rename-session -t 0 database   水平切割\n1 2  ctrl+b %   垂直切割\n1 2  ctrl+b \u0026#34;   建立新視窗\n1 2  ctrl+b c   上一個視窗\n1 2  ctrl+b p   下一個視窗\n1 2  ctrl+b n   依照編號直接切換（編號顯示於狀態列）\n1 2  ctrl+b \u0026lt;number\u0026gt;   視窗選單\n1 2  ctrl+b s   滑動視窗\n1 2  crtl+b [ q (離開)   進階 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  # 新增 $ tmux # OR $ tmux new -s \u0026lt;your_session_name\u0026gt; # session 列表 $ tmux ls # 重新連線 session $ tmux a -t 0 # OR $ tmux a -t \u0026lt;session_name\u0026gt; # 刪除 session $ tmux kill-session -t 0 # OR $ tmux kill-session -t \u0026lt;session_name\u0026gt; # OR $ tmux kill-session -a # 全部 # 刪除 tmux server $ tmux kill-server # 重新命名 session $ tmux rename-session -t 0 \u0026lt;new_session_name\u0026gt; # 快捷鍵/視窗管理 # C-b ? Help # C-b c 新增視窗 # C-b， 視窗命名 # C-b w 視窗列表 # C-b f 尋找視窗 # C-b \u0026amp; 刪除視窗 # C-b % 垂直分割區塊 # C-b “ 水平分割區塊 # C-b \u0026lt;方向鍵\u0026gt; # C-b p 上一個視窗 # C-b n 下一個視窗 # C-b \u0026lt;number\u0026gt; 依照編號直接切換（編號顯示於狀態列） # C-b d 離開 session # C-b x 關閉 Pane # C-d 關閉 Pane # C-b z 讓一個 Pane 變成全螢幕，在輸入一次則回到剛剛的尺寸   Reference  ssh自動連進tmux https://stackoverflow.com/questions/27613209/how-to-automatically-start-tmux-on-ssh-session 與iterm結合 https://medium.com/@wancw/iterm2-ssh-tmux-73d3fcf9dac6  ","date":"2022-05-30T13:32:31+08:00","image":"https://page.dipsyshih.com/p/linux%E7%B5%82%E7%AB%AF%E6%A9%9F%E8%A6%96%E7%AA%97%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7tmux%E7%AD%86%E8%A8%98/data_hu7fba9da1679ce4a56c592454604cb9c1_493914_120x120_fill_q75_box_smart1.jpg","permalink":"https://page.dipsyshih.com/p/linux%E7%B5%82%E7%AB%AF%E6%A9%9F%E8%A6%96%E7%AA%97%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7tmux%E7%AD%86%E8%A8%98/","title":"Linux終端機視窗管理工具tmux筆記"},{"content":"Google Interview Challenge https://www.1111.com.tw/1000w/fanshome/discussTopic.asp?cat=FANS\u0026id=301667\nhttps://www.gushiciku.cn/pl/gyQP/zh-tw\nhttps://hackernoon.com/14-patterns-to-ace-any-coding-interview-question-c5bb3357f6ed\nhttps://docs.google.com/spreadsheets/d/1yRCOJ8KysRVkq0O9IlDriT01tC6lzPapmFO4PCmDJQA/edit#gid=126913158 Google面試準備 刷題類型\n Arrays Binary Search Tree Binary Tree Dynamic Programming Greedy Graph – BFS、DFS Heap LinkedList Recursion Searching – Binary Search、Quick Select Stack String Sorting Topological sorting Trie  Google面試經典題目\n coin change coin change 2 Unique path Unique path 2 Permutation Permutation 2 subset subset 2 search in rotated sorted array search in rotated sorted array 2 word break word break 2 jump game jump game 2 word search word search 2 combination combination 2 meeting room meeting room 2 number of islands number of islands 2 number of distinct island number of distinct island 2  BQ準備 Imagine you worked in a project or a team that had a problematic culture Tell about the leading experience of a group project Thinking about a time you were given a large amount of work to complete under the tight deadline Tell about a time you face a problem without having clear solution How do you solve the conflict that happen in the team\nBlind 75 Array  Two Sum Best Time to Buy and Sell Stock Contains Duplicate Product of Array Except Self (M) Maximum Subarray Maximum Product Subarray Find Minimum in Rotated Sorted Array (M) Search in Rotated Sorted Array 3 Sum Container With Most Water  Binary  Sum of Two Integers Number of 1 Bits Counting Bits Missing Number Reverse Bits  Dynamic Programming  Climbing Stairs Coin Change Longest Increasing Subsequence Longest Common Subsequence Word Break Problem Combination Sum House Robber House Robber II Decode Ways Unique Paths Jump Game  Graph  Clone Graph Course Schedule Pacific Atlantic Water Flow (M) Number of Islands Longest Consecutive Sequence (M) Alien Dictionary (Leetcode Premium) (H) Key: directed graph + DFS or BFS Graph Valid Tree (Leetcode Premium) (M) Key: Check edges number first and then check unconnected component (Graph theory), Union Find! Number of Connected Components in an Undirected Graph (Leetcode Premium) (M)  Interval  Insert Interval Merge Intervals Non-overlapping Intervals (M) Key: greedy Meeting Rooms (Leetcode Premium) Meeting Rooms II (Leetcode Premium)  Linked List  Reverse a Linked List Detect Cycle in a Linked List Merge Two Sorted Lists Merge K Sorted Lists Remove Nth Node From End Of List Reorder List (M)  Matrix  Set Matrix Zeroes Spiral Matrix Rotate Image Word Search  String  Longest Substring Without Repeating Characters Longest Repeating Character Replacement Minimum Window Substring (H) Key: Optimized Sliding Windows! Valid Anagram Group Anagrams Valid Parentheses Valid Palindrome Longest Palindromic Substring Key: Manacher\u0026rsquo;s Algorithm Palindromic Substrings (M) Key: Manacher\u0026rsquo;s Algorithm Encode and Decode Strings (Leetcode Premium) (M)  Tree  Maximum Depth of Binary Tree Same Tree Invert/Flip Binary Tree Binary Tree Maximum Path Sum (H) Binary Tree Level Order Traversal (M) Serialize and Deserialize Binary Tree (H) Subtree of Another Tree Construct Binary Tree from Preorder and Inorder Traversal (M) Validate Binary Search Tree Kth Smallest Element in a BST (M) Lowest Common Ancestor of BST Implement Trie (Prefix Tree) (M) Add and Search Word (M) Word Search II  Heap  Merge K Sorted Lists Top K Frequent Elements (M) Find Median from Data Stream (H)  Tips https://hackernoon.com/14-patterns-to-ace-any-coding-interview-question-c5bb3357f6ed\nFunny One  Count Unique Characters of All Substrings of a Given String Key: really special solution Find the Duplicate Number Find Leaves of Binary Tree Split Array Largest Sum Key: Binary Search!!! Trapping Rain Water The Skyline Problem Key: Select the building with heapqueue Largest Rectangle in Histogram Key: tricky Apply with stack!!! Subtree of Another Tree Key: Markle Hash Substring with Concatenation of All Words Key: Sliding Window Longest Valid Parentheses key: Two pointer or DP or Stack Best Time to Buy and Sell Stock IV Key: Tricky One pass solution (DP or O(k) space) Design HashSet Key: Multiplicative hashing Unique Binary Search Trees Key: Catalan number! Shortest Path in a Grid with Obstacles Elimination Key: BFS + A* Student Attendance Record II Key: hardhard DP Guess the Word Key: Game theroy, compare with previous Min Cost to Connect All Points Key: minmun spanning tree!! (Prim\u0026rsquo;s or ) Path With Minimum Effort Key: Binary search space 132 Pattern Key: stack+min array  ","date":"2022-05-30T11:41:18+08:00","image":"https://page.dipsyshih.com/p/google-interview-leetcode-question-challenge/IMG_4879_hu9fbc77593f0c9272a39f6458a8217e4a_4615592_120x120_fill_q75_box_smart1.jpg","permalink":"https://page.dipsyshih.com/p/google-interview-leetcode-question-challenge/","title":"Google Interview Leetcode Question Challenge"},{"content":"我的台大魔幻之夜之路 前言 睽違三年再一次坐在台下欣賞台大魔夜 有別於當上下桌、表演者、核幹時看魔夜的各種緊張 我又再一次被這奇幻的晚會感動 回想大一時初次踏入社課看著鼎皓變著馬戲團騙術 轉眼間即將披上領巾準備畢業 四年來魔術社是家、是生活的重心、是不可分割的一部分 那麼就以這篇心得文來總結一下吧\n魔夜之路 起源 故事的開始起源於高中時一位魔術社的學長給我看了化內在Le plus的影片 影片放著 而他滔滔不絕的說著： 在遙遠的台大魔術社 有一群很厲害的魔術師 而且沒人知道為什麼他們這麼厲害 這讓我非常好奇 後來我得知這些人都曾上過台大魔幻之夜 那究竟是個怎麼樣的舞台呢 是不是真的跟傳聞一樣厲害？\n19魔《表演者聯盟》 機會很快的來臨 在寒假的Magic is Concept活動中意外的抽中了兩張19魔的門票 然後我遊說了詠辰還有社團的朋友一起去看 在那個只能看魔幻達人秀欣賞魔術的環境 台大魔幻之夜讓我看見魔術的新世界 九個厲害到爆表的表演和從頭讓人爆笑到尾的主持 這真是太厲害了 我總有一天一定要站上這個舞台\n20魔《Lumos》 高三下即使成為指考戰士 仍弄了張20魔的門票 無奈九點半只演完半場 只能打消看完魔夜的念頭 後來聽到下半場各種精彩 真的是十分後悔 若知道下一次能坐在台下看是四年後 大概會更後悔QQ\n21魔《21Hero》 然後就懞懞懂懂的上了台大 懞懞懂懂的加入了台大魔術社 懞懞懂懂的看著昀恆變魔術(昀恆抱歉QAQ我社課頗常消失…) 不知不覺的留給魔術的時間越來越少 直到有一天我還真的相信對魔術的熱情大概就到這了 然後詠辰突然告訴我他被找去當魔夜上下桌 在那裡他看到了很多厲害的東西 出於好奇 後來我也填了當上下桌 也很幸運的被選中 踏入二活這神聖的地方 我看見了許多不可思議的事 最初震撼我的是楊詒強到不行的表演 緊接著是各個表演者在長老日以繼夜的精雕細琢下 在極短的時間內快速的進化、蛻變 變成一個個屌炸天的表演 再次讓我相信 要成為台大魔夜的表演者並不是什麼遙不可及的夢想\n22魔《魔法師與他們的產地》 在魔夜症候群的驅使下考了教學 接受了一整年當幹部的洗禮 算是補了之前當新生時沒學好的種種 然後匆匆忙忙的完成了甄選程序 過了甄選後浪費了到一驗前的時間 開啟了各種趕進度的魔夜之路 經過了五驗的崩潰後 終於完成了自己還算滿意的程序 最後站上了台大魔幻之夜的舞台 完成了高中時對自己得承諾 一路上要感謝的人太多了 首先一定要感謝辛苦的核幹們 感謝你們相信我能夠上魔夜 並給予我機會\n 感謝 明翰 感謝你給我許多美感上的建議 還記得六驗後某一天我很崩潰時 你看我跑完後 默默的說了一句：跑的不錯 當下真的有種噴淚的衝動 感謝 昀恆 感謝你給我許多動作上的建議 也給我許多燈光上的建議 你的嚴格絕對是我們進步的動力 感謝 張騰 感謝你幫我解決道具上的疑難雜症 也感謝你時常鼓勵我給予精神上的支持 感謝 芃雅 感謝你時常帶許多東西來給我們吃 每次看到你來都有種被救贖的感覺 感謝 宣伯 在魔夜前期沒有方向的時候幾乎是以你的表演作為模板 也感謝後來不厭其煩的給我許多服裝上的建議 到了魔夜後期也花了不少時間幫我修程序 沒有你的幫忙我不可能生出這套程序 感謝 彥彥 感謝你總是能在各種時候給予鼓勵 縱使課業很忙 也還是空出時間來幫我修程序 讓我的程序越來越符合我心目中的樣子 感謝 小梅 給你修完之後總有突然進化的感覺 真的很喜歡你修的東西 也感謝你教我許多動作設計上的觀念 至今仍受用無窮 感謝 柏誠 高中時期就幫助我很多的學長 感謝你魔夜時幫我解決各種手法上的難題 感謝 化內 高中時期的偶像 雖然早就聽說你很嚴格 但我早已迫不及待請你幫我修程序了 感謝你幫我挑出許多動作上的瑕疵 也在程序初期決定方向時給了我許多很有用的建議 感謝 小鬼 感謝你總是能詳細且面面俱到的回答各種問題 每次驗收後根據影片給予的意見也是受益無窮 也感謝你解決了一些道具上的問題 感謝 En-Jui Shang 高中時期的偶像之二 感謝你抽空幫我修程序 你就如傳聞中一樣厲害 總能把看次普通的效果提升到另一個層次 感謝 子袁 感謝你常常出現在二活看我跑程序 也總能在我跑完後給予不少建議 感謝 小邱 感謝你總是默默出現在二活看我們練習 也總是不厭其煩的幫我們解決各種程序的bug 感謝 凌宇 感謝你時常來二活給予我們鼓勵 感謝 元廷 感謝你在程序初期給我許多建議 感謝 楊詒 感謝你給了我許多跳脫框架的建議 感謝 Michael Yang 感謝你在甄選前給予我道具上的意見 感謝 白菜 感謝你抽空幫我修程序 感謝 俊緯 感謝你在我做不出道具時給予協助 感謝 晉豪 感謝你陪我一起研究各種電路 雖然最後沒有用到QQ 感謝 Hsieh Kai Kai老師 感謝你能量滿滿的鼓勵 感謝 御伶 感謝你時常來二活陪我們練習 有你在的時候二活總是充滿快活的氣氛 感謝 昱先 在程序前期的時候很熱心的給我許多建議 感謝教學組的各位 感謝每次預講的各種歡樂總能紓解魔夜時的壓力 感謝 詠辰 能認識你真的太好了 從高中互相鼓勵一起上成發 到大學互相提攜一起上魔夜 不的不說你真的給了我很多上魔夜的動力 期待未來能我們能在各方面繼續發光發熱 感謝 How Jiun Hsu 感謝你當教學長總是那麼carry 也很佩服你在魔術上總有無窮無盡的想法 感謝 昌錦 總是在預講時提出許多想法 感謝 宣諭 感謝你總是那麼認真努力 激起了對魔術的熱血 感謝 杰勵 感謝你的各種梗 總能讓人會心一笑 感謝22魔的大家 感謝 祐增、 翁鈞、 德彥(BIMF加油餒)、 Davin Dai、 彥霓、 宥任、 孟豪、 晴晨、 皓屏 因為有你們 22魔才可以如此精彩  感謝台大眾多長老們的幫忙 我才得以站在台上 所有幫助過我的長老我都銘記在心 經歷過了魔夜才明白一人單打獨鬥是不足以撐起魔夜的 魔夜是長老們集體智慧的結晶 少了一點就不會如此完美了\n23魔《不能說的秘密》 又一次魔夜症候群發作 我接下了核幹 十分感謝上一屆核幹相信我能夠勝任這份工作 當核幹是我在魔術社裡學到最多東西的地方 包括各種行政事務、危機處理 如何辦好一場活動、如何規劃一場好的晚會 如何帶領一屆表演者 從什麼都不會到最後站上台大魔夜的舞台 而過程仍舊是要感謝台大眾多長老的幫忙\n感謝核幹夥伴  感謝社長皓鈞 感謝你總是如此的carry讓人放心 所有無解的問題到了你的手上似乎自然有了答案 感謝副社長宣諭 你細膩的心思總是能直接且俐落的給予表演者們心靈抑或是實質上的協助 也感謝你義無反顧的接下了舞台總監的位置 感謝執秘彥霓 感謝你在處理行政事務上的不遺餘力 也感謝你總是能給予表演者們精神上的鼓勵  感謝上屆核幹  感謝 昀恆 即便你課業繁忙 仍然投注大量的時間給魔術社 從給予表演者意見並協助表演者完成程序 到各種行政上的問題 沒有你23魔就不會如此順利 感謝 張騰 依舊感謝你各種道具力的支援 以及魔夜當天燈控的各種協助 沒有你魔夜不會這麼好看 感謝 明翰 感謝你協助宣傳品的製作 還有幫忙做帥翻天的開場片 感謝 芃雅 感謝你各種行政上的支援  感謝常回來的長老們  感謝 胖子 感謝你為這屆表演者費盡心思 還有你的炸海苔 感謝 白菜 感謝你時常回來幫忙盯表演者練習 感謝 小邱 也是感謝你時常回來幫忙盯表演者練習 感謝 詠辰 你就如同第五位核幹 處處協助著我們 感謝所有長老在百忙中撥空回來協助表演者 沒有你們不會有23魔 感謝 凱昇老師 你是台大魔夜的守護神  最後恭喜各位23魔的表演者 恭喜你們完成目標站上台大魔夜的舞台 感謝你們的堅持  感謝 荐泓 從什麼都不會的新生 到最終能獨當一面站上舞台的表演者 讓人看了真的很欣慰 感謝 Aaron 你真的是天才 總是能自己想出許多有趣的演繹 也不太需要我們擔心 感謝 家立 感謝持續不懈的努力 最終的表演也無愧於你的努力與長老的幫助 感謝 晉璿 你絕對是23魔最認真的表演者 從暑假到甄選前的練習 你從未有過任何怠惰 而你流暢的表演至今讓我印象深刻 也是不太需要核幹擔心的表演者 感謝 中漢 23魔喜劇擔當 比起帥氣的變魔術 搞笑大概更適合你 從準備甄選時就看得出你的積極 也很高興最後終於找對路 爆氣全場 感謝 御伶 感謝你一直以來對台大魔術社的熱愛 也恭喜你最終完成一套屬於你的而謝非常精彩的表演 感謝 雷邱 感謝你一直以來對魔術的熱情 也完成了一套相當厲害的程序 期待你之後的發展 感謝 謙煜 又是一個天才 你的霸氣是自然流露出來的 真的很厲害 也感謝你撐起了壓軸這個位置 也最終爆氣全場相當精彩 感謝主持 昱翔、 家儀、 晏榆 、 莎莎 感謝你們經常熬夜改劇本 也絞盡腦汁想出許多很不錯的梗 魔夜當天讓我從頭笑到尾 真的是非常好看的  當核幹輕不輕鬆 見仁見智 但壓力肯定是不會小的 畢竟一直以來台大魔夜以高水準著稱 而如今也輪到我們扛著這份壓力 但當看到最後的成果時 一切的付出皆值得了\n24魔《魔法師與理想國》 卸下了核幹的身份 有更多的時間嘗試自己想嘗試的事物 睽違三年再一次坐在台下欣賞台大魔夜 回到了初學魔術時 那樣興奮又期待的心情 而看完魔夜的那份感動 讓人久久不能自已 果然只有台大魔夜才能超越台大魔夜 台大魔夜就如同一場好長好長的夢 當它醒來之後 你會知道是時候好好面對自己的人生了 感謝這屆的核幹 感謝富淼、師傅、Aaron、晏榆 感謝你們竭盡餘力撐起社團 感謝這屆表演者 感謝你們撐過了各種驗收與考驗 各種辛苦將化為甜美的果實 希望你們都有享受到這充滿奇幻與魅力的舞台 感謝所有長老、凱昇老師 我們又再一次完成如此好看的晚會\n致謝 重要的人總是要放在最後 感謝父母 感謝你們容許我投注時間在魔術社上 僅管為了魔術社 已經很久沒有回家吃飯 很久沒有好好跟你們說話 你們卻不曾阻止過我 也感謝你們在能力有限的情況提供我資源 讓我有能力去嘗試 去挑戰 無論如何 你們才是我最該感謝的人 感謝 家儀 感謝你總是容許？我三不五時往魔術社跑 感謝你在我上魔夜時支持我專注於準備表演 感謝你在你上魔夜時沒有怨懟我時常要求你來練習 感謝你一直以來無條件的支持我、相信我 謝謝你 感謝 施星宇 感謝你堅強的心 感謝你不放棄的靈魂 最後感謝台大魔術社 當初的一個好奇 一不小心就花了四年的時間來探索 彷彿是一抸眼 卻說短也不短了 真的是一趟奇妙的旅程呢\n","date":"2019-05-19T16:50:00+08:00","image":"https://page.dipsyshih.com/p/%E6%88%91%E7%9A%84%E5%8F%B0%E5%A4%A7%E9%AD%94%E5%B9%BB%E4%B9%8B%E5%A4%9C%E4%B9%8B%E8%B7%AF/image_hu27f7dc34c9db8fd2b063f3fba6be9864_415116_120x120_fill_q75_box_smart1.jpg","permalink":"https://page.dipsyshih.com/p/%E6%88%91%E7%9A%84%E5%8F%B0%E5%A4%A7%E9%AD%94%E5%B9%BB%E4%B9%8B%E5%A4%9C%E4%B9%8B%E8%B7%AF/","title":"我的台大魔幻之夜之路"},{"content":"Datacube 函式筆記-基礎  API函式： 可以參考這個網站：https://nbviewer.jupyter.org/github/opendatacube/datacube-core/blob/develop/examples/notebooks/Datacube_Summary.ipynb 官方函式說明：https://datacube-core.readthedocs.io/en/latest/_modules/index.html 調整圖片顏色：http://xarray.pydata.org/en/stable/plotting.html 範例包：https://nbviewer.jupyter.org/github/opendatacube/datacube-core/tree/develop/examples/notebooks/ xarray用法：https://xarray.pydata.org/en/stable/generated/xarray.Dataset.html#xarray.Dataset https://xarray.pydata.org/en/stable/api.html#dataarray   ：Datacube class，建立一個Datacube項目，用來導入Datacube資料庫時會用到\n1 2  class datacube.Datacube(index=None, config=None, app=None, env=None, validate_connection=True)   範例：\n1 2 3 4  import datacube dc = datacube.Datacube(app = \u0026#39;my_app\u0026#39;, config = \u0026#39;/home/localuser/.datacube.conf\u0026#39;) #基本上就看你用的Datacube裡面的資料位置在哪，建議直接用     ：Datacube.list_products() \u0026amp; Datacube.list_measurements()\n Datacube.list_products()：列出所有的衛星資料 Datacube.list_measurements()：列出衛星資料所含有的波段種類 範例：  1 2 3 4 5  list_of_products = dc.list_products() netCDF_products = list_of_products[list_of_products[\u0026#39;format\u0026#39;] == \u0026#39;NetCDF\u0026#39;] netCDF_products #list_of_products的參數就照上面設，我也不知道差別在哪 #印出來就一個表格   1 2 3  list_of_measurements = dc.list_measurements() list_of_measurements #可以直接印出來，印出來也是一個表格     ：Datacube.load()，建立一個xarray.Dataset用來儲存要撈的資料的各種參數\n1 2 3 4  Datacube.load(product = None, measurements = None, output_crs = None, resolution = None, resampling = None, dask_chunks = None, like = None, fuse_func = None, align = None, datasets = None, **query)   範例1：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  import datetime # define geographic boundaries in (min, max) format # 用兩個變數來儲存要找的經緯度範圍(方框)，我也不知道多邊形怎麼用 lon = (120.3697, 120.5044) lat = (23.6686, 23.7476) # define date range boundaries in (min,max) format # 用datetime格式來儲存要提取資料的時間範圍 date_range =(datetime.datetime(2016,1,1), datetime.datetime(2017,6,30)) # define product and platform to specify our intent to #load Landsat 8 sr products platform = \u0026#39;LANDSAT_8\u0026#39; # 衛星資料的模板，其實可以不用打，要打就不要打錯 product = \u0026#39;ls8_lasrc_taiwan\u0026#39; # 用來辨識讀取哪一個衛星的資料，絕對不能打錯 # define desired bands. desired_bands = [\u0026#39;red\u0026#39;,\u0026#39;green\u0026#39;,\u0026#39;blue\u0026#39;,\u0026#39;nir\u0026#39;,\u0026#39;swir1\u0026#39;,\u0026#39;swir2\u0026#39;,\u0026#39;pixel_qa\u0026#39;] # 要提取的波段資料 # 以Landset8的話共有coastal_aerosol、blue、green、red、nir、swir1、swir2、 # lwir1、lwir2、pixel_qa、sr_aerosol、radsat_qa這些波段，我們只提取了其中幾個，也可以在加 # 輸出的順序會按照陣列的裡的排列出現 # load area. Should result in approximately 15 #acquisitions between 2014 and 2016 landsat = dc.load(product = product,platform = platform, lat = lat,lon = lon,time = date_range, measurements = desired_bands) landsat # 然後實際把資料load出來，回傳的格式是xarray.Dataset   範例2：\n1 2 3 4 5 6  dc.load(product=\u0026#39;ls5_nbar_albers\u0026#39;, x=(148.15, 148.2), y=(-35.15, -35.2), time=(\u0026#39;1990\u0026#39;, \u0026#39;1991\u0026#39;), # 時間座標等也可以用上面這種表示法 x=(1516200, 1541300), y=(-3867375, -3867350), crs=\u0026#39;EPSG:3577\u0026#39; # 也可以這樣，只是就要附註crs # 時間也可以用上面那種方法 output_crs=\u0026#39;EPSG:3577`, resolution=(-25, 25), resampling=\u0026#39;cubic\u0026#39;)     ：Datacube.find_datasets()、Datacube.group_datasets()、Datacube.load_data()\n Datacube.find_datasets()：列出符合條件的影像資料位置，以list方式回傳 Datacube.group_datasets()：將上面find_datasets()回傳的list裡的資料group起來，也可以自己弄一個符合格式的檔案路徑list，然後一樣嘢可幫你group起來 Datacube.load_data()：把剛剛group起來的資料load出來  1 2 3 4 5 6 7 8 9  Datacube.find_datasets(**search_terms) # 參數的部分要輸入一種特殊的Query型態，不過datacube怪怪的，不能import這種格式 # 所以等下範例有直接輸入參數的方式 Datacube.group_datasets(datasets, group_by) # 放棄嘗試這個函式XDD 主要是不知道group_by參數要填什麼 # 就是傳入上面那個find_datasets return 的東西 # 會回傳先前看到的xarray.DataArray格式 Datacube.load_data(sources, geobox, measurements, resampling=None, fuse_func=None, dask_chunks=None, skip_broken_datasets=False) # 也是放棄嘗試這個函式XDD # 傳入剛剛group_datasets弄好的xarray，然後傳出xarray.Dataset   範例：\n1 2  dc.find_datasets(product = \u0026#39;ls8_lasrc_taiwan\u0026#39;, time = (\u0026#39;2016-01-01\u0026#39;, \u0026#39;2017-01-01\u0026#39;)) # 然後就會回傳一個list，裡面有所有符合條件資料的位置     ：加入crs資料 其實這步可以不用做，基本上就是把讀取的參數整合\n1 2 3 4 5 6 7  import xarray as xr import numpy as np # xarray是用來儲存讀取資料的格式 combined_dataset = xr.merge([landsat]) # Copy original crs to merged dataset combined_dataset = combined_dataset.assign_attrs(landsat.attrs) combined_dataset     ：實際撈資料\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  import time # 裡面有把時間轉為字串的函式 import rasterio # 將點狀資料轉成圖塊 from dc_utilities import write_geotiff_from_xr # 這蠻重要的，可以將xr格式轉成geotiff格式 def time_to_string(t): # 將時間轉為字串 return time.strftime(\u0026#34;%Y_%m_%d_%H_%M_%S\u0026#34;, time.gmtime(t.astype(int)/1000000000)) # 就採用`time.strftime`函數將時間轉為字串，等等用來加入檔名當中 def export_slice_to_geotiff(ds, path): # 將資料轉為實際的tiff檔案 write_geotiff_from_xr(path,ds.astype(np.float32),list(landsat.data_vars.keys()),crs=\u0026#34;EPSG:4326\u0026#34;) # 在這裡引用了write_geotiff_from_xr()函數，path是新建的tiff檔案的路徑和檔名， # ds.astype(np.float32)是將原來資料裡的整數值轉為浮點數值，大概是因為這個函數只接受浮點數， # list(landsat.data_vars.keys())則是將這裡面所有的屬性質(就是nir、red、blue那些)轉成list形式而已 # 最後crs就不必說惹，可以試一下怎麼直接從原來那個xarray.Dataset讀取這個資料，手動輸入實在很智障 #For each time slice in a dataset we call export_slice_to_geotif def export_xarray_to_geotiff(ds, path): for t in ds.time: # 接著就根據xarrayDataset.time裡面的時間資料list一筆一筆抓出來處理 time_slice_xarray = ds.sel(time = t) # 先是搞一個新的xarray，然後把裡面的time換成單一的值(有點像是從一層抽出一片的感覺)，以便等會用write_geotiff_from_xr轉換 export_slice_to_geotiff(time_slice_xarray, path + \u0026#34;_\u0026#34; + time_to_string(t) + \u0026#34;.tif\u0026#34;) # 然後就呼叫export_slice_to_geotiff，其實就是write_geotiff_from_xr()函數 #Start Export output_dir = \u0026#34;/home/localuser/Datacube/data_cube_notebooks/NTUF_Hsing-Yu/ToTiffTest\u0026#34; # 存檔的路徑 if not os.path.exists(output_dir): # 資料夾存在就直接存，沒有就新建一個 os.makedirs(output_dir) export_xarray_to_geotiff(landsat, \u0026#34;{}/{}\u0026#34;.format(output_dir,product)) # \u0026#34;{}/{}\u0026#34;.format(output_dir,product)的用法還沒有研究     ：資料繪圖plot() 在xarray.Dataset的格式下可以直接呼叫plot()函數匯出影像\n 範例1：  1 2 3 4 5  autumn = nbar.green.loc[\u0026#39;1991-3\u0026#39;:\u0026#39;1991-5\u0026#39;] # 圖檔的話好像只能用單一波段繪圖， 所以這邊要選擇你要的波段 # 這邊是選綠色，然後後面那邊可以設定時間區間，似乎也是可以不用設定！？ autumn.shape # 看一下格式這樣 autumn.plot(col=\u0026#39;time\u0026#39;, col_wrap=3) # 然後印出圖形，橫軸按照時間排列，每一排三個 # 印出來之後就向下圖這樣    範例2：去除nodata的版本：  1 2  autumn_valid = autumn.where(autumn != autumn.attrs[\u0026#39;nodata\u0026#39;]) # 新建一個變數，用來儲存去除nodata的資料 autumn_valid.plot(col=\u0026#39;time\u0026#39;, col_wrap=3) # 然後一樣輸出    範例3：去除雲 在landsat5以後的衛星資料會提供一個pixelquality波段，通常是用來表示該相素的含雲量，有幾個特定的值是表示該像素是可以用的，不過我忘了  1 2 3 4  pq = dc.load(product=\u0026#39;ls5_pq_albers\u0026#39;, x=(149.25, 149.35), y=(-35.25, -35.35)) # 一樣先load做出xarray.Dataset ，可以注意到這邊load的版本是ls5_pq_albers，跟前面load的nbar版本不一樣 pq_autumn = pq.pixelquality.loc[\u0026#39;1991-3\u0026#39;:\u0026#39;1991-5\u0026#39;] # 然後一樣，只是改成以pixelquality波段作圖 pq_autumn.plot(col=\u0026#39;time\u0026#39;, col_wrap=3) # 顯示出來就像下面那樣   可以注意到有特殊顏色的就是含雲量較高的像素，正常應該是黃色，所以等等要將這些有色區塊去除 這邊會用到masking工具，可以從datacube.storage中取出來\n1 2 3 4 5  from datacube.storage import masking # 取出masking工具 import pandas pandas.DataFrame.from_dict(masking.get_flags_def(pq), orient=\u0026#39;index\u0026#39;) # 這裡的masking.get_flags_def(pq)，是從原來的xarray.Dataset找到如何判斷pixelquality值的表 # 然後就會得到一個對照表   1 2 3 4 5 6 7  good_data = masking.make_mask(pq, cloud_acca=\u0026#39;no_cloud\u0026#39;, cloud_fmask=\u0026#39;no_cloud\u0026#39;, contiguous=True) # 接下來要建立一個新的mask，mask上顏色不同的地方就是判定有雲的地方 # 根據前面的表，只要把cloud_acca和cloud_fmask這兩個變數都設為\u0026#39;no_cloud\u0026#39;，而contiguous=True則是表示這個pixel還含有其他波段， # 可以試試設成false會怎樣 # 這樣就可以做出一個mask autumn_good_data = good_data.pixelquality.loc[\u0026#39;1991-3\u0026#39;:\u0026#39;1991-5\u0026#39;] # 然後再一次實際套用到剛剛的xarray.Dataset上 autumn_good_data.plot(col=\u0026#39;time\u0026#39;, col_wrap=3) # 印出來就如下圖   可以發現，現在不是黃色就是紫色 最後拿去跟一開始有綠色波段且做過nodata處理的那張圖疊\n1 2  autumn_cloud_free = autumn_valid.where(autumn_good_data) # 就跟用來疊nodata的作法一樣 autumn_cloud_free.plot(col=\u0026#39;time\u0026#39;, col_wrap=3) # 印出來就像下面那樣   可以發現原本有雲的地方都變成無資料了，因為mask裡面，有雲的地方，數字被設為0，沒有雲的地方為1\n後來發現mask不給力，landsat8的資料不太能用，因此我就直接用where取出pixel_qa為322的資料 範例：\n1 2 3 4 5 6  autumn = combined_dataset.green.where(combined_dataset.pixel_qa == 322) # 取值為322的資料，這是landsat8中品質最好的資料 autumn_valid = autumn.where(autumn != autumn.attrs[\u0026#39;nodata\u0026#39;]) # 一樣清除nodata autumn_valid.plot(col=\u0026#39;time\u0026#39;, col_wrap=10) # 印出來就像下面那樣(顏色沒有調得很好XDD)     ：將圖群組化(超重要！！) 有時候因為衛星軌道的關係，一個地區的影像會被切成兩三張圖放，用Group可將時間相近的圖整合成一張\n 範例：  1 2 3  nbar_by_solar_day = dc.load(product=\u0026#39;ls5_nbar_albers\u0026#39;, x=(149.25, 149.35), y=(-35.25, -35.35), group_by=\u0026#39;solar_day\u0026#39;) # 大部分跟之前用load()的方式差不多，只是在最後加了group_by=\u0026#39;solar_day\u0026#39;就是根據太陽日的範圍群組化圖 len(nbar_by_solar_day.time) # 看一下圖是不是真的變少了   1 2  autumn2 = nbar_by_solar_day.green.loc[\u0026#39;1991-3\u0026#39;:\u0026#39;1991-5\u0026#39;] # 一樣取出綠色的波段作圖 autumn2.shape   1  autumn2.plot(col=\u0026#39;time\u0026#39;, col_wrap=3) # 一樣畫出圖，就變下面那樣   可以發現原來切掉的部分不見了！！！\n  ：算ndvi 就用red和nir這兩個波段算出ndvi，大概就是可以反映出地面物是不是植物這樣 red就是紅光，nir就是近紅外光\n1 2 3 4 5 6 7 8 9 10 11 12  two_bands = dc.load(product=\u0026#39;ls5_nbar_albers\u0026#39;, x=(149.07, 149.17), y=(-35.25, -35.35), time=(\u0026#39;1991\u0026#39;, \u0026#39;1992\u0026#39;), measurements=[\u0026#39;red\u0026#39;, \u0026#39;nir\u0026#39;], group_by=\u0026#39;solar_day\u0026#39;) # 跟前面使用load()的方式差不多，不過這次要用measurements，同時只load\u0026#39;red\u0026#39;, \u0026#39;nir\u0026#39;這兩個波段，一樣要記得用group_by red = two_bands.red.where(two_bands.red != two_bands.red.attrs[\u0026#39;nodata\u0026#39;]) # 然後去除nodata nir = two_bands.nir.where(two_bands.nir != two_bands.nir.attrs[\u0026#39;nodata\u0026#39;]) # 也是去除nodata pq = dc.load(product=\u0026#39;ls5_pq_albers\u0026#39;, x=(149.07, 149.17), y=(-35.25, -35.35), time=(\u0026#39;1991\u0026#39;, \u0026#39;1992\u0026#39;), group_by=\u0026#39;solar_day\u0026#39;) # 然後load另一個圖(是pq版本的)，等等用來做could free的mask cloud_free = masking.make_mask(pq, cloud_acca=\u0026#39;no_cloud\u0026#39;, cloud_fmask=\u0026#39;no_cloud\u0026#39;, contiguous=True).pixelquality # 用之前坐的那張圖做一個mask，一樣取出pixelquality的部分 ndvi = ((nir - red) / (nir + red)).where(cloud_free) # 拿nir和red這兩張圖算一下ndvi，然後跟cloud_free疊加，去除雲的部分 ndvi.shape # 看一下資料量 ndvi.plot(col=\u0026#39;time\u0026#39;, col_wrap=5) # 印出來，就像下面那樣   其實還是有很多地方被切掉XDD，而且圖像的品質參差，接下來可以取出影像品質比較好的幾張，也就是含雲量較少的\n1 2 3 4  mostly_cloud_free = cloud_free.sum(dim=(\u0026#39;x\u0026#39;,\u0026#39;y\u0026#39;)) \u0026gt; (0.75 * cloud_free.size / cloud_free.time.size) # 簡單來說就是找含雲量前25%少的圖 mostly_good_ndvi = ndvi.where(mostly_cloud_free).dropna(\u0026#39;time\u0026#39;, how=\u0026#39;all\u0026#39;) # 然後拿去跟原來的疊，刪掉雲多的圖 mostly_good_ndvi.plot(col=\u0026#39;time\u0026#39;, col_wrap=5) # 印出來   就發現只剩清晰的圖了 以下是我用先前桃園市的資料算的ndvi\n1 2 3 4 5 6 7 8  red = combined_dataset.red.where(combined_dataset.red != combined_dataset.red.attrs[\u0026#39;nodata\u0026#39;]).where(combined_dataset.pixel_qa == 322) nir = combined_dataset.nir.where(combined_dataset.nir != combined_dataset.nir.attrs[\u0026#39;nodata\u0026#39;]).where(combined_dataset.pixel_qa == 322) # 跟上面差不多，取出red和nir兩個波段，然後用where取出pixel_qa為322的地方 ndvi = ((nir - red) / (nir + red)).where(ndvi \u0026lt;= 1).where(ndvi \u0026gt;= -1) # 套個ndvi的公式 ndvi.shape ndvi.plot(col=\u0026#39;time\u0026#39;, col_wrap=5) # 印出來   接下來挑選一下雲含量比較少的圖\n1 2 3 4 5 6 7 8 9  cloud_free = combined_dataset.pixel_qa.where(combined_dataset.pixel_qa != combined_dataset.pixel_qa.attrs[\u0026#39;nodata\u0026#39;]).where(combined_dataset.pixel_qa == 322) / 322 # 這邊就用先前pixel_qa的圖，抓值為322的部分，rescale為1，偽造成一個mask #cloud_free.plot(col=\u0026#39;time\u0026#39;, col_wrap=3) mostly_cloud_free = cloud_free.sum(dim=(\u0026#39;latitude\u0026#39;,\u0026#39;longitude\u0026#39;)) \u0026gt; (0.75 * cloud_free.size / cloud_free.time.size) # 然後去算裡面不是雲的資料的比例，其實就是把它加總這樣 mostly_good_ndvi = ndvi.where(mostly_cloud_free).dropna(\u0026#39;time\u0026#39;, how=\u0026#39;all\u0026#39;) # 然後疊一下圖 mostly_good_ndvi.plot(col=\u0026#39;time\u0026#39;, col_wrap=5) # 印出來   第一張圖估計是系統弄錯惹，都是雲，但值是322，將就著看吧 接下來ndvi還可以組一張中位數的圖，有點類似平均值的概念，可以看大範圍完整的樣子，不會受到圖片卻失的影響\n1 2  mostly_good_ndvi.median(dim=\u0026#39;time\u0026#39;).plot() # 就是取出每一個pixel的中位數，組成一張圖，這個函式還蠻厲害ㄉ   印出來就像這樣，顏色較深的地方大概就是沒有植物啦哈哈 p.s.為什麼不用平均數呢？因為平均數會受到nodata的影響 然後也可以做一張std的圖，表示變化程度\n1 2  mostly_good_ndvi.std(dim=\u0026#39;time\u0026#39;).plot() # 概念跟剛剛median差不多   顏色較淺的地方就是變化量較大的地方，ndvi會隨季節變化，這個大家都知道ㄉ，所以一樣，亮的地方就是有植物的地方\n然後也可以抓單一一點的ndvi變化，所以我隨便用google map選了一點 引用sel函式，後面輸入參數，可以讀出該座標上每個時間的值\n1  mostly_good_ndvi.sel(latitude=24.958132, longitude=121.126085, method=\u0026#39;nearest\u0026#39;).plot()   畫出來的圖，某種程度上還是會受到nodata的影響\n下面這個是範例的奇妙用法，好像是抓出ndvi趨勢的感覺，詳細機制還要再研究\n1 2  mostly_good_ndvi.isel(latitude=[200], longitude=[200]).plot() # 那個兩百我不知道是要幹嘛的，我有試試看其他值，但跑出來的圖都怪怪的   這張圖就可以很明顯的看到ndvi的季節性變化了\n接下來也是範例的奇妙用法，可以固定緯度，將不同時間的情況列出來\n1 2  mostly_good_ndvi.isel(longitude=30).plot() # 30的意義好像是代表longitude的第30個pixel   這樣一比對還真的可以看出明顯的季節變化\n另外還可以抓出特定幾個點比較時間的影響\n1 2  mostly_good_ndvi.isel_points(latitude=[0, 10, 20, 30, 40, 50], longitude=[20, 30, 40, 50, 60, 70]).plot(x=\u0026#39;points\u0026#39;, y=\u0026#39;time\u0026#39;) # 同上那些數值也是以座標而言的第幾個點這樣     ：多頻譜製圖(不是做成tif) 玩久了之後還是會想要做一張彩色的圖自爽一下 以下的方法就可以惹\n1 2 3 4 5  rgb = dc.load(product=product, lon=lon, lat=lat, time=date_range, measurements=[\u0026#39;red\u0026#39;, \u0026#39;green\u0026#39;, \u0026#39;blue\u0026#39;], group_by=\u0026#39;solar_day\u0026#39;).to_array(dim=\u0026#39;color\u0026#39;).transpose(\u0026#39;time\u0026#39;, \u0026#39;latitude\u0026#39;, \u0026#39;longitude\u0026#39;, \u0026#39;color\u0026#39;) # 前面坐過很多次了，就不贅述，紅綠藍波段一定要load近來，load了其他波段我不知道會怎樣，有空再試試 # 後面就是新建一個dim為新的color zip(rgb.dims, rgb.shape) # 有沒有做這個zip其實沒差   1 2 3 4 5 6 7 8  fake_saturation = 3000 # 這個是用來當作影像值得上限，超過就用3000取代 clipped_visible = rgb.where(rgb \u0026lt; fake_saturation).fillna(fake_saturation) # 上面這邊就是這樣做，透過fillna()函式可以填入值 max_val = clipped_visible.max([\u0026#39;latitude\u0026#39;, \u0026#39;longitude\u0026#39;]) # 然後找最大的scale scaled = (clipped_visible / max_val) # 設定scaled   1 2 3  from matplotlib import pyplot as plt plt.imshow(scaled.isel(time=19)) # 最後就印出來，記得要import該import的東西   選了一張被雲遮比較少ㄉ\n  ：將xarray.Dataarray製成Dataset http://xarray.pydata.org/en/stable/generated/xarray.DataArray.to_dataset.html https://stackoverflow.com/questions/38826505/python-xarray-add-dataarray-to-dataset\n  ：Dataarray or Dataset中的資料型別轉換 http://xarray.pydata.org/en/stable/generated/xarray.DataArray.astype.html\n  ：不想要用.varibales的替代方案.get() https://github.com/pydata/xarray/issues/1801\n  ：將matplotlib畫出的東西輸出成png https://stackoverflow.com/questions/9622163/save-plot-to-image-file-instead-of-displaying-it-using-matplotlib\n    Datacube 函式筆記-進階  WOFs  Datacube 函式筆記-其他  文件解壓縮 在可以使用sever Shell的情況下，通常將文件打包(.zip)上傳之後再用Linux下的unzip解壓縮，不過新版的jupyter介面將Shell的功能關惹，所以只能用python內建的函式庫解壓縮，程式如下：  1 2 3 4 5 6 7 8 9 10 11 12  import os,zipfile def un_zip(file_name): \u0026#34;\u0026#34;\u0026#34;unzip zip file\u0026#34;\u0026#34;\u0026#34; zip_file = zipfile.ZipFile(file_name) if os.path.isdir(file_name + \u0026#34;_files\u0026#34;): pass else: os.mkdir(file_name + \u0026#34;_files\u0026#34;) for names in zip_file.namelist(): zip_file.extract(names,file_name + \u0026#34;_files/\u0026#34;) zip_file.close() un_zip(\u0026#34;utils.zip\u0026#34;)   使用方式：先用%指令切換到正確的工作目錄，然後啟動run上面的程式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  import os, zipfile #打包目录为zip文件（未压缩） def make_zip(source_dir, output_filename): zipf = zipfile.ZipFile(output_filename, \u0026#39;w\u0026#39;) pre_len = len(os.path.dirname(source_dir)) for parent, dirnames, filenames in os.walk(source_dir): for filename in filenames: print(filename) pathfile = os.path.join(parent, filename) arcname = pathfile[pre_len:].strip(os.path.sep) #相对路径 zipf.write(pathfile, arcname) print() zipf.close() make_zip(r\u0026#34;E:\\python_sample\\libs\\test_tar_files\\libs\u0026#34;,\u0026#34;test.zip\u0026#34;)    Jupyter使用終端機指令 雖然終止了shell的使用，但一樣可以在Jupyter使用Linux指令，不過一樣會受到權限限制 ex:  1 2 3  % ls % cd ~ % pwd   ","date":"2019-03-22T00:58:25+08:00","image":"https://i.imgur.com/ilufKDH.png","permalink":"https://page.dipsyshih.com/p/datacube-%E5%87%BD%E5%BC%8F%E7%AD%86%E8%A8%98/","title":"Datacube 函式筆記"}]